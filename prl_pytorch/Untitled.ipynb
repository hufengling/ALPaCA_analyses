{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8942ac47-b728-4f20-b73b-c03f8f474f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#bsub -q lpcgpu -gpu \"num=1\" -n 2 -J \"train_predictor[1-10]\" -o ~/Documents/prl/stdout/predictor_05.txt bash -c \"python /home/fengling/Documents/prl/prl_pytorch/_06_joint_train.py\"\n",
    "import os\n",
    "from random import randrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchio as tio\n",
    "import _01_dataloader_small as prl_dl\n",
    "import _02_autoencoder as prl_ae\n",
    "import _09_solo_predictor as prl_pred\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(prl_dl)\n",
    "#importlib.reload(prl_ae)\n",
    "#importlib.reload(prl_pred)\n",
    "\n",
    "def isolate_lesion(patches_batch):\n",
    "    lesion_mask_tensor = patches_batch[\"lesion_mask\"][\"data\"]\n",
    "    mask_tensor = torch.zeros_like(lesion_mask_tensor)\n",
    "    for i in range(lesion_mask_tensor.size()[0]):\n",
    "        tmp_lesion_mask = lesion_mask_tensor[i, :, :, :, :].clone()\n",
    "        lesion_ids = tmp_lesion_mask.unique()\n",
    "        lesion_ids = lesion_ids[lesion_ids != 0]\n",
    "\n",
    "        if (len(lesion_ids) > 1): # Only need to blackout lesion if there are two lesions.\n",
    "            id_to_keep = lesion_ids[randrange(len(lesion_ids))]\n",
    "            mask_tensor[i, :, :, :, :] = 0.1 * torch.ones_like(tmp_lesion_mask) + 0.9 * ((tmp_lesion_mask == 0) + (tmp_lesion_mask == id_to_keep))\n",
    "        else:\n",
    "            mask_tensor[i, :, :, :, :] = torch.ones_like(tmp_lesion_mask)\n",
    "            \n",
    "    return(mask_tensor.repeat(1, 4, 1, 1, 1))\n",
    "\n",
    "def get_lesion_type(patches_batch, isolation_mask_tensor):\n",
    "    lesion_type_tensor = patches_batch[\"lesion_type\"][\"data\"][:, 0, :, :, :]\n",
    "    isolation_mask = (isolation_mask_tensor[:, 0, :, :, :] - 0.1) * 10 / 9 # Originally is a [batch, 4, 24, 24, 24] tensor\n",
    "    isolated_lesion_type = lesion_type_tensor * isolation_mask\n",
    "\n",
    "    batch_size = isolated_lesion_type.size()[0]\n",
    "    target_tensor = torch.zeros(batch_size, 3)\n",
    "    weight_tensor = torch.zeros(batch_size, 3)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        tmp_unique = isolated_lesion_type[i, :, :, :].unique()\n",
    "        tmp_unique = int(tmp_unique[len(tmp_unique) - 1].item())\n",
    "        print(tmp_unique)\n",
    "        target_tensor[i, :], weight_tensor[i, :] = process_lesion_type(tmp_unique, \n",
    "                                                                       patches_batch[\"contains_lesions\"][i], \n",
    "                                                                       patches_batch[\"contains_cvs\"][i])\n",
    "\n",
    "    return([target_tensor, weight_tensor])\n",
    "\n",
    "def process_lesion_type(lesion_id, contains_lesions, contains_cvs): # Return tensor of [is_lesion, is_PRL, is_CVS]\n",
    "    target = torch.zeros(3)\n",
    "    weight = torch.ones(3)\n",
    "    weight[1] = 1\n",
    "    weight[2] = 1\n",
    "    \n",
    "    if contains_lesions == False:\n",
    "        weight[0] = 0\n",
    "    if contains_cvs == False:\n",
    "        weight[2] = 0\n",
    "   \n",
    "    digits = [int(x) for x in str(lesion_id)] \n",
    "    # First digit is always 1 for computational convenience\n",
    "   \n",
    "    if (lesion_id == 0):\n",
    "        return([target, weight]) # Just return the tensor of 0 for target and normal weights\n",
    "    \n",
    "    if digits[1] == 1: # standard lesion\n",
    "        weight[0] = 1\n",
    "        target[0] = 1\n",
    "        \n",
    "    if digits[2] == 1: # PRL lesion\n",
    "        weight[0] = 1\n",
    "        target[0] = 1\n",
    "        weight[1] = 1\n",
    "        target[1] = 1\n",
    "    \n",
    "    if digits[3] == 1: # CVS lesion\n",
    "        weight[0] = 1\n",
    "        target[0] = 1\n",
    "        weight[2] = 1\n",
    "        target[2] = 1\n",
    "    \n",
    "    return([target, weight])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lesion_autoencoder = prl_ae.Autoencoder3D()\n",
    "prl_autoencoder = prl_ae.Autoencoder3D()\n",
    "cvs_autoencoder = prl_ae.Autoencoder3D()\n",
    "lesion_autoencoder = lesion_autoencoder.to(device)\n",
    "prl_autoencoder = prl_autoencoder.to(device)\n",
    "cvs_autoencoder = cvs_autoencoder.to(device)\n",
    "\n",
    "model_path = \"/home/fengling/Documents/prl/prl_pytorch/cv_models/prl_autoencoder_05_\" + str(prl_dl.i) + \".pt\"\n",
    "\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the state_dict from the checkpoint\n",
    "lesion_autoencoder.load_state_dict(checkpoint)\n",
    "prl_autoencoder.load_state_dict(checkpoint)\n",
    "cvs_autoencoder.load_state_dict(checkpoint)\n",
    "\n",
    "lesion_predictor = prl_pred.Predictor3D()\n",
    "lesion_predictor = lesion_predictor.to(device)\n",
    "prl_predictor = prl_pred.Predictor3D()\n",
    "prl_predictor = prl_predictor.to(device)\n",
    "cvs_predictor = prl_pred.Predictor3D()\n",
    "cvs_predictor = cvs_predictor.to(device)\n",
    "\n",
    "lesion_optimizer = torch.optim.Adam(lesion_predictor.parameters(), lr=0.001)\n",
    "lesion_joint_optimizer = torch.optim.Adam(list(lesion_autoencoder.encoder.parameters()) + \n",
    "                                   list(lesion_predictor.parameters()), \n",
    "                                   lr=0.001)\n",
    "prl_optimizer = torch.optim.Adam(prl_predictor.parameters(), lr=0.001)\n",
    "prl_joint_optimizer = torch.optim.Adam(list(prl_autoencoder.encoder.parameters()) + \n",
    "                                   list(prl_predictor.parameters()), \n",
    "                                   lr=0.001)\n",
    "cvs_optimizer = torch.optim.Adam(cvs_predictor.parameters(), lr=0.001)\n",
    "cvs_joint_optimizer = torch.optim.Adam(list(cvs_autoencoder.encoder.parameters()) + \n",
    "                                   list(cvs_predictor.parameters()), \n",
    "                                   lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "keys = [\"t1\", \"flair\", \"epi\", \"phase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8a21e0-46da-457d-ad57-bfe6fdb7bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.ones((64, 4, 24, 24, 24))\n",
    "lesion_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "lesion_output_tensor = prl_predictor(lesion_encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3234dd8c-6111-4111-b337-504740ee2290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesion_output_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c0a7c5-96a6-4ef8-8e40-1125d291d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1909\n",
      "1909\n",
      "0\n",
      "1909\n",
      "1909\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_19667/2938470307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlesion_output_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mlesion_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlesion_output_tensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mprl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprl_output_tensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mcvs_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvs_output_tensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/pkg/mamba/envs/nnbatch-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/pkg/mamba/envs/nnbatch-env/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/pkg/mamba/envs/nnbatch-env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "for epoch_index in range(num_epochs):\n",
    "    epoch_loss = [0, 0, 0]\n",
    "    \n",
    "    # First train the predictor to catch up to pre-trained encoder\n",
    "    if epoch_index <= num_epochs * 0.1:\n",
    "        for patches_batch in prl_dl.train_loader:\n",
    "            lesion_optimizer.zero_grad()\n",
    "            prl_optimizer.zero_grad()\n",
    "            cvs_optimizer.zero_grad()\n",
    "\n",
    "            isolation_mask_tensor = isolate_lesion(patches_batch)\n",
    "            target_tensor, weight_tensor = get_lesion_type(patches_batch, isolation_mask_tensor)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "            weight_tensor = weight_tensor.to(device)\n",
    "            \n",
    "            print(target_tensor[:, 0:1].size())\n",
    "            print(weight_tensor.size())\n",
    "\n",
    "            input_tensor = torch.cat([patches_batch.get(key)[\"data\"] for key in keys], dim=1) * isolation_mask_tensor\n",
    "            input_tensor = input_tensor.to(device)\n",
    "\n",
    "            lesion_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "            lesion_output_tensor = prl_predictor(lesion_encoded_tensor)\n",
    "            prl_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "            prl_output_tensor = prl_predictor(prl_encoded_tensor)\n",
    "            cvs_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "            cvs_output_tensor = prl_predictor(cvs_encoded_tensor)\n",
    "\n",
    "            print(lesion_output_tensor.size())\n",
    "            lesion_loss = nn.BCELoss()(lesion_output_tensor * weight_tensor[:, 0:1], target_tensor[:, 0:1] * weight_tensor[:, 0:1])\n",
    "            prl_loss = nn.BCELoss()(prl_output_tensor * weight_tensor[:, 1:2], target_tensor[:, 1:2] * weight_tensor[:, 1:2])\n",
    "            cvs_loss = nn.BCELoss()(cvs_output_tensor * weight_tensor[:, 2:3], target_tensor[:, 2:3] * weight_tensor[:, 2:3])\n",
    "            lesion_loss.backward()\n",
    "            prl_loss.backward()\n",
    "            cvs_loss.backward()\n",
    "            lesion_optimizer.step()\n",
    "            prl_optimizer.step()\n",
    "            cvs_optimizer.step()\n",
    "\n",
    "            epoch_loss += [float(lesion_loss), float(prl_loss), float(cvs_loss)]\n",
    "        print(\"Batch \" + str(epoch_index) + \": Loss = \" + str(epoch_loss))\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, train both predictor and encoder together\n",
    "    for patches_batch in prl_dl.train_loader:\n",
    "        lesion_joint_optimizer.zero_grad()\n",
    "        prl_joint_optimizer.zero_grad()\n",
    "        cvs_joint_optimizer.zero_grad()\n",
    "\n",
    "        isolation_mask_tensor = isolate_lesion(patches_batch)\n",
    "        target_tensor, weight_tensor = get_lesion_type(patches_batch, isolation_mask_tensor)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        weight_tensor = weight_tensor.to(device)\n",
    "\n",
    "        input_tensor = torch.cat([patches_batch.get(key)[\"data\"] for key in keys], dim=1) * isolation_mask_tensor\n",
    "        input_tensor = input_tensor.to(device)\n",
    "\n",
    "        lesion_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "        lesion_output_tensor = prl_predictor(lesion_encoded_tensor)\n",
    "        prl_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "        prl_output_tensor = prl_predictor(prl_encoded_tensor)\n",
    "        cvs_encoded_tensor = prl_autoencoder.get_latent(torch.clone(input_tensor))\n",
    "        cvs_output_tensor = prl_predictor(cvs_encoded_tensor)\n",
    "        \n",
    "        lesion_loss = nn.BCELoss()(lesion_output_tensor * weight_tensor[:, 0], target_tensor[:, 0] * weight_tensor[:, 0])\n",
    "        prl_loss = nn.BCELoss()(prl_output_tensor * weight_tensor[:, 1], target_tensor[:, 1] * weight_tensor[:, 1])\n",
    "        cvs_loss = nn.BCELoss()(cvs_output_tensor * weight_tensor[:, 2], target_tensor[:, 2] * weight_tensor[:, 2])\n",
    "        lesion_loss.backward()\n",
    "        prl_loss.backward()\n",
    "        cvs_loss.backward()\n",
    "        lesion_joint_optimizer.step()\n",
    "        prl_joint_optimizer.step()\n",
    "        cvs_joint_optimizer.step()\n",
    "\n",
    "        epoch_loss += [float(lesion_loss), float(prl_loss), float(cvs_loss)]\n",
    "    print(\"Batch \" + str(epoch_index) + \": Loss = \" + str(epoch_loss))\n",
    "        \n",
    "torch.save(lesion_autoencoder.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/lesion_joint_05_\" + str(prl_dl.i) + \".pt\")\n",
    "torch.save(lesion_predictor.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/lesion_predictor_05_\" + str(prl_dl.i) + \".pt\")\n",
    "\n",
    "torch.save(prl_autoencoder.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/prl_joint_05_\" + str(prl_dl.i) + \".pt\")\n",
    "torch.save(prl_predictor.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/prl_predictor_05_\" + str(prl_dl.i) + \".pt\")\n",
    "\n",
    "torch.save(cvs_autoencoder.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/cvs_joint_05_\" + str(prl_dl.i) + \".pt\")\n",
    "torch.save(cvs_predictor.state_dict(), \"/home/fengling/Documents/prl/prl_pytorch/cv_individual_models/cvs_predictor_05_\" + str(prl_dl.i) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef4e85-d261-44ac-8db7-268a8ebc3415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnbatch-env",
   "language": "python",
   "name": "nnbatch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
