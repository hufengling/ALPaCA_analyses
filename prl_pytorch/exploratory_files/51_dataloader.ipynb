{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb929b5-be44-471f-a79f-ae2097ce7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchio as tio\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "images_dir = \"/home/fengling/Documents/prl/data/processed\"\n",
    "subjects_df = pd.read_csv(\"/home/fengling/Documents/prl/prl_pytorch/data/cv_df.csv\")\n",
    "\n",
    "if os.getenv(\"LSB_JOBINDEX\") == None:\n",
    "    i = 1\n",
    "else:\n",
    "    i = int(os.getenv(\"LSB_JOBINDEX\"))\n",
    "\n",
    "train = subjects_df[\"subject_id\"][subjects_df[\"cv_index\"] != i - 1].values.tolist()\n",
    "test = subjects_df[\"subject_id\"][subjects_df[\"cv_index\"] == i - 1].values.tolist()\n",
    "\n",
    "      \n",
    "# Data loader settings\n",
    "transforms = [\n",
    "    tio.RandomAffine(\n",
    "        scales=(0.66, 1.5), \n",
    "        degrees=180,\n",
    "        isotropic=True\n",
    "    ),\n",
    "    tio.RandomFlip()\n",
    "]\n",
    "transform = tio.Compose(transforms)\n",
    "\n",
    "patch_size = 24\n",
    "queue_length = 500\n",
    "samples_per_volume = 50\n",
    "num_workers = 20\n",
    "sampler = tio.data.WeightedSampler(patch_size, \"prob\")\n",
    "\n",
    "# Train set data loader\n",
    "train_dir = [os.path.join(images_dir, x) for x in train]\n",
    "\n",
    "train_subject_list = []\n",
    "for subject_path in train_dir:\n",
    "    file_paths = [os.path.join(subject_path, x) for x in os.listdir(subject_path)]\n",
    "    subject = tio.Subject(\n",
    "        epi = tio.ScalarImage([s for s in file_paths if \"epi_final.nii.gz\" in s][0]),\n",
    "        flair = tio.ScalarImage([s for s in file_paths if \"flair_final.nii.gz\" in s][0]),\n",
    "        phase = tio.ScalarImage([s for s in file_paths if \"phase_final.nii.gz\" in s][0]),\n",
    "        t1 = tio.ScalarImage([s for s in file_paths if \"t1_final.nii.gz\" in s][0]),\n",
    "        prob = tio.ScalarImage([s for s in file_paths if \"prob.nii.gz\" in s][0]),\n",
    "        lesion_mask = tio.LabelMap([s for s in file_paths if \"prob_01.nii.gz\" in s][0]),\n",
    "        lesion_type = tio.LabelMap([s for s in file_paths if \"lesion_labels.nii.gz\" in s][0]),\n",
    "        name = subject_path\n",
    "    )\n",
    "    train_subject_list.append(subject)\n",
    "\n",
    "train_dataset = tio.SubjectsDataset(train_subject_list, transform = transform)\n",
    "\n",
    "train_queue = tio.Queue(\n",
    "    train_dataset,\n",
    "    queue_length,\n",
    "    samples_per_volume,\n",
    "    sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_queue,\n",
    "    batch_size=64,\n",
    "    num_workers=0,  # this must be 0\n",
    ")\n",
    "\n",
    "# Test set data loader\n",
    "test_dir = [os.path.join(images_dir, x) for x in test]\n",
    "\n",
    "test_subject_list = []\n",
    "for subject_path in test_dir:\n",
    "    file_paths = [os.path.join(subject_path, x) for x in os.listdir(subject_path)]\n",
    "    subject = tio.Subject(\n",
    "        epi = tio.ScalarImage([s for s in file_paths if \"epi_final.nii.gz\" in s][0]),\n",
    "        flair = tio.ScalarImage([s for s in file_paths if \"flair_final.nii.gz\" in s][0]),\n",
    "        phase = tio.ScalarImage([s for s in file_paths if \"phase_final.nii.gz\" in s][0]),\n",
    "        t1 = tio.ScalarImage([s for s in file_paths if \"t1_final.nii.gz\" in s][0]),\n",
    "        prob = tio.ScalarImage([s for s in file_paths if \"prob.nii.gz\" in s][0]),\n",
    "        lesion_mask = tio.LabelMap([s for s in file_paths if \"prob_01.nii.gz\" in s][0]),\n",
    "        lesion_type = tio.LabelMap([s for s in file_paths if \"lesion_labels.nii.gz\" in s][0]),\n",
    "        name = subject_path\n",
    "    )\n",
    "    test_subject_list.append(subject)\n",
    "\n",
    "test_dataset = tio.SubjectsDataset(test_subject_list)\n",
    "\n",
    "test_queue = tio.Queue(\n",
    "    test,\n",
    "    queue_length,\n",
    "    samples_per_volume,\n",
    "    sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_queue,\n",
    "    batch_size=64,\n",
    "    num_workers=0,  # this must be 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "132a102c-9553-44e5-ab39-235085983a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5c730f-890f-489a-8c85-503183534e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello1.pt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello\" + str(i) + \".pt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
