{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845ea64a-4909-45ff-afe3-eeb5e38ce38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import _01_dataloader_small as prl_dl\n",
    "import _02_autoencoder as prl_ae\n",
    "import _05_predictor as prl_pred\n",
    "\n",
    "import importlib\n",
    "importlib.reload(prl_dl)\n",
    "importlib.reload(prl_ae)\n",
    "importlib.reload(prl_pred)\n",
    "\n",
    "def patch_to_tensor(patch):\n",
    "    patch_list = [patch.get(key)[\"data\"] for key in keys]\n",
    "    #for i in range(len(patch_list)):\n",
    "     #   patch_list[i] = patch_list[i][None, :]\n",
    "    patch_tensor = torch.cat(patch_list, dim=0)\n",
    "    return patch_tensor[None, :]\n",
    "\n",
    "def plot_3d_tensor(subject, autoencoder, coord = [10, 10, 10]):\n",
    "    patch = prl_dl.train_loader.dataset[subject]\n",
    "    \n",
    "    tensor1 = patch_to_tensor(patch)\n",
    "    tensor2 = autoencoder(tensor1)\n",
    "    \n",
    "    print(patch[\"name\"])\n",
    "    print(patch[\"location\"][0:3] + torch.tensor([12, 12, 12]))\n",
    "    \n",
    "    for image in range(4):\n",
    "        # Plot first tensor\n",
    "        tensor1_tmp = tensor1[0, image, :, :, :]\n",
    "\n",
    "        # Extract the slice at the given coordinate\n",
    "        slice_x = tensor1_tmp[coord[0], :, :].detach().numpy()\n",
    "        slice_y = tensor1_tmp[:, coord[1], :].detach().numpy()\n",
    "        slice_z = tensor1_tmp[:, :, coord[2]].detach().numpy()\n",
    "\n",
    "        # Create subplots for the three axes\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        # Plot slices in each axis\n",
    "        axes[0].imshow(slice_x, cmap='gray')\n",
    "        axes[0].set_title('X-axis Slice')\n",
    "\n",
    "        axes[1].imshow(slice_y, cmap='gray')\n",
    "        axes[1].set_title('Y-axis Slice')\n",
    "\n",
    "        axes[2].imshow(slice_z, cmap='gray')\n",
    "        axes[2].set_title('Z-axis Slice')\n",
    "\n",
    "        # Adjust spacing between subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "        # Plot second tensor\n",
    "        tensor2_tmp = tensor2[0, image, :, :, :]\n",
    "        \n",
    "        # Extract the slice at the given coordinate\n",
    "        slice_x = tensor2_tmp[coord[0], :, :].detach().numpy()\n",
    "        slice_y = tensor2_tmp[:, coord[1], :].detach().numpy()\n",
    "        slice_z = tensor2_tmp[:, :, coord[2]].detach().numpy()\n",
    "\n",
    "        # Create subplots for the three axes\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        # Plot slices in each axis\n",
    "        axes[0].imshow(slice_x, cmap='gray')\n",
    "        axes[0].set_title('X-axis Slice')\n",
    "\n",
    "        axes[1].imshow(slice_y, cmap='gray')\n",
    "        axes[1].set_title('Y-axis Slice')\n",
    "\n",
    "        axes[2].imshow(slice_z, cmap='gray')\n",
    "        axes[2].set_title('Z-axis Slice')\n",
    "\n",
    "        # Adjust spacing between subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "prl_autoencoder = prl_ae.Autoencoder3D()\n",
    "prl_autoencoder_joint = prl_ae.Autoencoder3D()\n",
    "prl_predictor = prl_pred.Predictor3D()\n",
    "\n",
    "keys = [\"t1\", \"flair\", \"epi\", \"phase\"]\n",
    "\n",
    "# Load the state_dict from the checkpoint\n",
    "prl_autoencoder.load_state_dict(torch.load(\"models/prl_autoencoder_0718_upweight.pt\", \n",
    "                                           map_location=torch.device('cpu')))\n",
    "prl_autoencoder.eval()\n",
    "\n",
    "# Load the state_dict from the checkpoint\n",
    "prl_autoencoder_joint.load_state_dict(torch.load(\"models/prl_autoencoder_joint_0719.pt\", \n",
    "                                           map_location=torch.device('cpu')))\n",
    "prl_autoencoder_joint.eval()\n",
    "\n",
    "# Load the state_dict from the checkpoint\n",
    "prl_predictor.load_state_dict(torch.load(\"models/prl_predictor_0719.pt\", \n",
    "                                           map_location=torch.device('cpu')))\n",
    "prl_predictor.eval()\n",
    "\n",
    "def process_lesion_type(lesion_id): # Return tensor of [is_lesion, is_PRL, is_CVS]\n",
    "    target = torch.zeros(3)\n",
    "    weight = torch.ones(3)\n",
    "    if (lesion_id == 0):\n",
    "        return([target, weight]) # Just return the tensor of 0s\n",
    "\n",
    "    digits = [int(x) for x in str(lesion_id)] \n",
    "    # First digit is always 1 for computational convenience\n",
    "    \n",
    "    if digits[1] == 1: # non-PRL lesion\n",
    "        target[0] = 1\n",
    "\n",
    "    if digits[1] == 2: # PRL lesion\n",
    "        target[0] = 1\n",
    "        target[1] = 1\n",
    "\n",
    "    if digits[2] == 1: # non-CVS lesion\n",
    "        target[0] = 1\n",
    "\n",
    "    if digits[2] == 3:\n",
    "        target[0] = 1\n",
    "        target[2] = 1\n",
    "        \n",
    "    if digits[2] == 2: # possible CVS \n",
    "        target[0] = 1\n",
    "        weight[2] = 0 # Don't count errors in CVS column against the network\n",
    "    \n",
    "    if digits[2] == 9: # no CVS data available for this subject\n",
    "        target[0] = -1\n",
    "        target[2] = -1\n",
    "        weight[0] = 0 # Don't count errors in lesion detection or CVS detection lesion coverage in PRL dataset is poor\n",
    "        weight[2] = 0 \n",
    "\n",
    "    return([target, weight])\n",
    "\n",
    "def get_coords(candidate_id, num_coords, \n",
    "               lesion_mask):\n",
    "    candidate_coords = torch.nonzero(lesion_mask == candidate_id)\n",
    "    max_coords = min(num_coords, candidate_coords.size()[0])\n",
    "    random_inds = random.sample(range(candidate_coords.size()[0]), max_coords)\n",
    "    return(candidate_coords[random_inds, :])\n",
    "\n",
    "def isolate_lesion(lesion_mask_patch, candidate_id):\n",
    "    isolation_mask = (lesion_mask_patch == 0) + (lesion_mask_patch == candidate_id)\n",
    "\n",
    "    if (isolation_mask == False).any():\n",
    "        return([True, isolation_mask])\n",
    "    else:\n",
    "        return([False, isolation_mask])\n",
    "\n",
    "def extract_patch(coord, candidate_id, \n",
    "                  t1, flair, epi, phase, \n",
    "                  lesion_mask, lesion_type):\n",
    "    start_ends = [coord[1] - 12, coord[1] + 12, \n",
    "                  coord[2] - 12, coord[2] + 12,\n",
    "                  coord[3] - 12, coord[3] + 12]\n",
    "    x_start = max(start_ends[0], 0)\n",
    "    x_end = min(start_ends[1], t1.size()[1] - 1)\n",
    "    y_start = max(start_ends[2], 0)\n",
    "    y_end = min(start_ends[3], t1.size()[2] - 1)\n",
    "    z_start = max(start_ends[4], 0)\n",
    "    z_end = min(start_ends[5], t1.size()[3] - 1)\n",
    "\n",
    "    t1_patch = t1[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "    flair_patch = flair[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "    epi_patch = epi[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "    phase_patch = phase[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "\n",
    "    patch = torch.cat((t1_patch, flair_patch, epi_patch, phase_patch))\n",
    "    lesion_mask_patch = lesion_mask[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "    lesion_type_patch = lesion_type[:, x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "    if tuple(patch.size()) != (4, 24, 24, 24):\n",
    "        patch, lesion_mask_patch, lesion_type_patch = pad_patches(patch, lesion_mask_patch, \n",
    "                                                                  lesion_type_patch, start_ends)\n",
    "    is_multiple, isolation_mask = isolate_lesion(lesion_mask_patch, candidate_id)\n",
    "\n",
    "    if is_multiple:\n",
    "        patch = patch * (isolation_mask.repeat(4, 1, 1, 1))\n",
    "        lesion_id = (lesion_type_patch * isolation_mask).unique()\n",
    "        lesion_id = lesion_id[lesion_id != 0]\n",
    "    else:\n",
    "        lesion_id = lesion_type_patch.unique()\n",
    "        lesion_id = lesion_id[lesion_id != 0]\n",
    "\n",
    "    return([patch, lesion_id])\n",
    "\n",
    "def pad_patches(patch, lesion_mask_patch, lesion_type_patch, \n",
    "                start_ends):\n",
    "    patch_pad_tensor = torch.zeros(4, 24, 24, 24)\n",
    "    mask_pad_tensor = torch.zeros(1, 24, 24, 24)\n",
    "    type_pad_tensor = torch.zeros(1, 24, 24, 24)\n",
    "    starts = [start_ends[i] for i in [0, 2, 4]]\n",
    "    start_patch = [0 - start if start < 0 else 0 for start in starts]\n",
    "    ends = [start_ends[i] for i in [1, 3, 5]]\n",
    "    end_patch = [23 - (ends[i] - t1.size()[i + 1]) if ends[i] >= t1.size()[i + 1] else 24 for i in range(len(ends))]\n",
    "\n",
    "    patch_pad_tensor[:, \n",
    "                     start_patch[0]:end_patch[0], \n",
    "                     start_patch[1]:end_patch[1], \n",
    "                     start_patch[2]:end_patch[2]] = patch\n",
    "    mask_pad_tensor[:, \n",
    "                     start_patch[0]:end_patch[0], \n",
    "                     start_patch[1]:end_patch[1], \n",
    "                     start_patch[2]:end_patch[2]] = lesion_mask_patch\n",
    "    type_pad_tensor[:, \n",
    "                     start_patch[0]:end_patch[0], \n",
    "                     start_patch[1]:end_patch[1], \n",
    "                     start_patch[2]:end_patch[2]] = lesion_type_patch\n",
    "    \n",
    "    return(patch_pad_tensor, mask_pad_tensor, type_pad_tensor)\n",
    "\n",
    "def get_predictions(dataset, subject_id, num_coords):\n",
    "    subject = dataset[subject_id]\n",
    "    print(subject[\"name\"])\n",
    "\n",
    "    lesion_mask = subject[\"lesion_mask\"][\"data\"]\n",
    "    lesion_type = subject[\"lesion_type\"][\"data\"]\n",
    "\n",
    "    t1 = subject[\"t1\"][\"data\"]\n",
    "    flair = subject[\"flair\"][\"data\"]\n",
    "    epi = subject[\"epi\"][\"data\"]\n",
    "    phase = subject[\"phase\"][\"data\"]\n",
    "\n",
    "    output_tensor = torch.zeros(int(lesion_mask.max()), 3)\n",
    "    target_tensor = torch.zeros(int(lesion_mask.max()), 3)\n",
    "\n",
    "    for candidate_id in range(1, int(lesion_mask.max()) + 1):\n",
    "        coords = get_coords(candidate_id, num_coords, lesion_mask)\n",
    "        tmp_coord = coords[0, :]\n",
    "        target_tensor[candidate_id - 1, :] = process_lesion_type(int(lesion_type[tmp_coord[0], tmp_coord[1], tmp_coord[2], tmp_coord[3]]))[0]\n",
    "        prediction = torch.zeros(num_coords, 3)\n",
    "\n",
    "        for i in range(coords.size()[0]):\n",
    "            coord = coords[i, :]\n",
    "            patch, lesion_id = extract_patch(coord, candidate_id, \n",
    "                                             t1, flair, epi, phase,\n",
    "                                            lesion_mask, lesion_type)\n",
    "            patch = patch[None, :, :, :, :]\n",
    "            output = prl_predictor(prl_autoencoder_joint.encoder(patch))\n",
    "            prediction[i, :] = output\n",
    "\n",
    "        if num_coords > 1:\n",
    "            output_tensor[candidate_id - 1, :] = torch.mean(prediction, dim=0)\n",
    "        else:\n",
    "            output_tensor[candidate_id - 1, :] = prediction\n",
    "\n",
    "        #print(\"Mean prediction: \" + str(output_tensor[candidate_id - 1, :]))\n",
    "    \n",
    "    return([subject[\"name\"], output_tensor, target_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced28beb-e3a3-4496-917e-22e03b108f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "for i in range(len(prl_dl.train_dataset)):\n",
    "    tmp_name, tmp_output, tmp_target = get_predictions(prl_dl.train_dataset, i, 20)\n",
    "    tmp_df = pd.DataFrame(torch.cat([tmp_output, tmp_target], dim=1).detach().numpy())\n",
    "    tmp_df[\"subject\"] = tmp_name\n",
    "    train_df = pd.concat([train_df, tmp_df])\n",
    "train_df.to_csv(\"data/train_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe579bc-4e8b-4d6c-9337-691212f16c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_test = prl_dl.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2def665a-c3b3-4b70-8735-601be4126582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fengling/Documents/prl/data/processed/01-008'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prl_test[9][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a099b-b273-40d1-8990-bca637cfb355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fengling/Documents/prl/data/processed/05-001\n",
      "/home/fengling/Documents/prl/data/processed/07-006\n",
      "/home/fengling/Documents/prl/data/processed/07-012\n",
      "/home/fengling/Documents/prl/data/processed/02-009\n",
      "/home/fengling/Documents/prl/data/processed/08-002\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "for i in range(len(prl_dl.test_dataset)):\n",
    "    tmp_name, tmp_output, tmp_target = get_predictions(prl_dl.train_dataset, i, 20)\n",
    "    tmp_df = pd.DataFrame(torch.cat([tmp_output, tmp_target], dim=1).detach().numpy())\n",
    "    tmp_df[\"subject\"] = tmp_name\n",
    "    test_df = pd.concat([test_df, tmp_df])\n",
    "test_df.to_csv(\"data/test_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3acbc-53fa-4c0e-83fe-c3b74718aec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
